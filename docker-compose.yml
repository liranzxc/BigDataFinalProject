version: '2.1'
services:
  spark-master:
    image: bde2020/spark-master:2.4.4-hadoop2.7
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
  spark-worker-1:
    image: bde2020/spark-worker:2.4.4-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    expose:
      - "2181"
    volumes:
      - kafka_zookeeper:/opt/zookeeper-3.4.13/data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.11

  kafka1:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka1
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.12
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka1:/opt/kafka_2.12-2.2.0/logs
    networks:
      kafkanet:
        ipv4_address: 172.25.0.12
    depends_on:
      - "zookeeper"
  kafka_manager:
    image: hlebalbau/kafka-manager:1.3.3.18
    container_name: kafka_manager
    expose:
      - "9000"
    environment:
      ZK_HOSTS: "172.25.0.11:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
    depends_on:
      - "zookeeper"
      - "kafka1"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.14

  producer:
    build:
      dockerfile: ./Dockerfile
      context: .
    command: python producer_main.py
    depends_on:
      - "zookeeper"
      - "kafka1"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.13

  consumer:
    build:
      dockerfile: ./Dockerfile
      context: .
    command: python consumer_main.py
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "mongodb"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.15


  mongodb:
    image: 'bitnami/mongodb:4.0'
    ports:
      - "27017:27017"
    volumes:
      - 'mongodb_data:/bitnami'


networks:
  kafkanet:
    name: kafkanet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16
          gateway: 172.25.0.1

volumes:
  mongodb_data:
    driver: local
  kafka_zookeeper:
  kafka_kafka1:




## docker-compose up -d
## will create a spark on background