

for started a spark cluster first you need to download :

- docker
- docker-compose

in the root project we have docker-compose
you must be in "CMD" or terminal on the directory that contains docker-compose

# execute command : docker-compose up -d

please wait  , cluster spark will be created  ( master + 1 worker)

on the project have spark_example folder that contains a test script . please run him before started .

the script connected to spark and execute a "ADD" operation .

please note need to pip install all packages .

have fun :)
